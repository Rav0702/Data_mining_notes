{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Locality Sensitive Hashing (LSH)\n",
    "Locality-Sensitive Hashing (LSH) is a technique used to solve the approximate or exact near-neighbour search problem in high-dimensional spaces. The basic idea behind LSH is to hash similar items to the same “buckets” with high probability, while hashing dissimilar items to different buckets with high probability. This allows for efficient search of large datasets, as items that are similar will be found in the same bucket and can be compared more quickly than items that are dissimilar.\n",
    "\n",
    "LSH has many applications, including nearest neighbour search, clustering, image and text retrieval, and recommendation systems. It has been successfully applied to problems in computer vision, information retrieval, data mining, and machine learning.\n",
    "\n",
    "- Retrieval of nearest neighbours of a query point q using LSH works as follows:\n",
    "    - Hash all data points using locality-sensitive hash\n",
    "    - Compute locality-sensitive hash of query point\n",
    "    - All data points in the bucket are candidate near neighbours\n",
    "    - Compute distances to candidate points to find true nearest neighbours\n",
    "- Locality-sensitive hashing can be used with minhash\n",
    "signatures:\n",
    "• Divide signature matrix into b bands consisting of r rows each\n",
    "• Hash each sub-signature of length r into a hash table per band\n",
    "• Two sets with at least one identical sub-signature will hash in\n",
    "the same bucket (at least once)\n",
    "    → Candidate column pairs for similarity\n",
    "\n",
    "### Normal vs. LSH\n",
    "\n",
    "- Normal hash functions try to minimize the probability of collision\n",
    "- LSH hash functions try to maximize probability of similar items colliding\n",
    "\n",
    "### Problem with LSH Projections\n",
    "\n",
    "![Collision and Split](../assets/collision.png)\n",
    "\n",
    "Collision and Split\n",
    "\n",
    "********AND-Construction →******** Using multiple projections in an LSH resolves “collisions”. Points are candidates if they occur in all query bins\n",
    "\n",
    "****************************OR-Construction →****************************  Using multiple separate hash tables when doing LSH resolves “splits”. Points are candidate neighbours if candidate in any of the hash tables\n",
    "\n",
    "### LSH in Space Summary\n",
    "\n",
    "- Hashes are done using random projections\n",
    "- Combining projections using AND reduces FP and slightly increases FN\n",
    "- Combining sets of projections using OR reduces FN and slightly increases FP\n",
    "- Cascading AND/OR constructions for optimal performance\n",
    "\n",
    "### Banding\n",
    "\n",
    "Banding is a technique used in Locality-Sensitive Hashing (LSH) to improve the efficiency of the hashing process. It involves dividing the signature matrix into \"bands,\" which consist of a certain number of rows. Each band is then hashed separately, and the resulting hash values are combined to generate an overall hash value for the signature. This technique can help to reduce the number of false positives in the LSH process, improving the accuracy of the results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# a should be similar to b\n",
    "a = \"This is an amazing test string that tests similarity\"\n",
    "b = \"This is another amazing test string that also tests similarity\"\n",
    "c = \"I am completly unrelated\"\n",
    "\n",
    "dataset = [\n",
    "  a, b, c\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Shingles"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def shingle(text: str, k: int):\n",
    "  return {text[i:i+k] for i in range(len(text)-k+1)}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "vocabulary = list(functools.reduce(lambda a, b: a.union(b), [shingle(i, 2) for i in dataset]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def one_hot(vocabulary, shingles):\n",
    "  return [1 if i in shingles else 0 for i in vocabulary]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "transformed_dataset = [one_hot(vocabulary, shingle(i, 2)) for i in dataset]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Signatures\n",
    "\n",
    "Signatures are short integer vectors that represent the sets, and reflect their similarity\n",
    "\n",
    "## MinWise Hashing\n",
    "\n",
    "Minwise hashing is a technique used in Locality-Sensitive Hashing to estimate the similarity between two sets. It works by representing a set as a series of hash values, and then comparing the hash values of two sets to estimate their similarity.\n",
    "\n",
    "### Algorithm\n",
    "\n",
    "1. Initialize a set of hash functions H.\n",
    "2. For each element in the set, compute the minimum hash value for each hash function in H.\n",
    "3. The resulting set of minimum hash values is the signature of the set.\n",
    "\n",
    "### Example\n",
    "\n",
    "Suppose we have two sets, A = {1, 2, 3, 4} and B = {2, 3, 5, 7}. We can use minwise hashing to estimate their similarity as follows:\n",
    "\n",
    "1. Choose two hash functions, h1(x) = (3x + 1) mod 5 and h2(x) = (5x + 2) mod 7.\n",
    "2. Compute the minimum hash values for each set:\n",
    "\n",
    "    A: h1(1) = 4, h2(1) = 3\n",
    "    h1(2) = 1, h2(2) = 0\n",
    "    h1(3) = 4, h2(3) = 5\n",
    "    h1(4) = 2, h2(4) = 0\n",
    "    Signature(A) = {1, 0, 4, 0}\n",
    "\n",
    "    B: h1(2) = 1, h2(2) = 0\n",
    "    h1(3) = 4, h2(3) = 5\n",
    "    h1(5) = 0, h2(5) = 0\n",
    "    h1(7) = 3, h2(7) = 3\n",
    "    Signature(B) = {0, 0, 4, 0}\n",
    "\n",
    "3. The Jaccard similarity between A and B can be estimated as the fraction of components in their signatures that are equal:\n",
    "\n",
    "    Jaccard(A, B) ≈ 2/4 = 0.5\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class MinHash:\n",
    "  def __init__(self, size, hash_functions_count: int):\n",
    "    self.permutations = [list(range(size)) for i in range(hash_functions_count)]\n",
    "    for i in self.permutations:\n",
    "      random.shuffle(i)\n",
    "\n",
    "  def get_signature(self, X):\n",
    "    sign = []\n",
    "    for permutation in self.permutations:\n",
    "      for i in permutation:\n",
    "        if X[i] == 1:\n",
    "          sign.append(i)\n",
    "          break;\n",
    "    return sign\n",
    "\n",
    "minhasher = MinHash(len(vocabulary), 20)\n",
    "signatures = [minhasher.get_signature(i) for i in transformed_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def jaccard_similarity(A: set, B: set) -> float:\n",
    "  union = A.union(B)\n",
    "  intersection = A.intersection(B)\n",
    "  return len(intersection)/len(union)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_similarity(set(signatures[0]), set(signatures[1]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "0.037037037037037035"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_similarity(set(signatures[1]), set(signatures[2]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Locality Sensitive Hashing Implementation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "[[17, 40, 52, 12],\n [20, 20, 13, 23],\n [54, 49, 52, 57],\n [15, 49, 51, 36],\n [38, 28, 11, 12]]"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_signature(signature, b):\n",
    "  assert len(signature) % b == 0\n",
    "  return [signature[i:i+b] for i in range(0, len(signature), b)]\n",
    "split_signature(signatures[1],4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 with 1 are pairs?  True\n",
      "1 with 2 are pairs?  False\n",
      "0 with 2 are pairs?  False\n"
     ]
    }
   ],
   "source": [
    "def are_candidate_pairs(signA, signB, bands):\n",
    "  splitA = split_signature(signA, bands)\n",
    "  splitB = split_signature(signB, bands)\n",
    "\n",
    "  return any([a==b for a,b in zip(splitA, splitB)])\n",
    "print(\"0 with 1 are pairs? \", are_candidate_pairs(signatures[0],signatures[1],4))\n",
    "print(\"1 with 2 are pairs? \", are_candidate_pairs(signatures[1],signatures[2],4))\n",
    "print(\"0 with 2 are pairs? \", are_candidate_pairs(signatures[0],signatures[2],4))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
